{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNf1H50/25MG+9rTsNhKnR+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yugesh18c/GenAIAssignments/blob/main/Assignment4/AS4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlB7fEIur6lg",
        "outputId": "f6d93339-2bbf-49a8-91bb-b92ae2a024e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi\n"
          ]
        }
      ],
      "source": [
        "print(\"hi\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai faiss-cpu pandas tqdm --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss8nRnRRv8lb",
        "outputId": "88e39de2-71db-4bca-ffa3-8d4f5412447b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importaing libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import faiss\n",
        "from tqdm import tqdm\n",
        "from typing import List, Tuple\n",
        "from openai import AzureOpenAI"
      ],
      "metadata": {
        "id": "mJ7OKOhcwA3a"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Environment setup and variables\n",
        "\n",
        "os.environ[\"OPENAI_API_VERSION\"] = \"2024-02-15-preview\"\n",
        "os.environ[\"OPENAI_DEPLOYMENT_NAME\"] = \"text-embedding-ada-002\"\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = '04f9a983b5d747baac8c74a75c0d525a'\n",
        "os.environ['OPENAI_ENDPOINT'] = 'https://swedencentral.api.cognitive.microsoft.com/'"
      ],
      "metadata": {
        "id": "PSlzI6iOv5-J"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AZURE_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DEPLOYMENT_NAME\")\n",
        "\n",
        "# Azure client\n",
        "client = AzureOpenAI(\n",
        "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "    api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
        "    azure_endpoint=os.getenv(\"OPENAI_ENDPOINT\")\n",
        ")"
      ],
      "metadata": {
        "id": "Ox8NYjmrwd58"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_json('/content/sample_data/self_critique_loop_dataset.json') #Read locally uploaded JSON file. This path will change based on where JSON file is placed\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RLDbD3kVn-JO",
        "outputId": "8b144e49-c8b1-4ecc-b51a-8a5ae1aeb6b7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  doc_id                                           question  \\\n",
              "0  KB001             What are best practices for debugging?   \n",
              "1  KB002    What are best practices for performance tuning?   \n",
              "2  KB003               What are best practices for caching?   \n",
              "3  KB004  What are best practices for asynchronous progr...   \n",
              "4  KB005        What are best practices for API versioning?   \n",
              "\n",
              "                                      answer_snippet  \\\n",
              "0  When addressing debugging, it's important to f...   \n",
              "1  When addressing performance tuning, it's impor...   \n",
              "2  When addressing caching, it's important to fol...   \n",
              "3  When addressing asynchronous programming, it's...   \n",
              "4  When addressing API versioning, it's important...   \n",
              "\n",
              "                              source confidence_indicator last_updated  \n",
              "0                 debugging_guide.md             moderate   2024-01-10  \n",
              "1        performance tuning_guide.md             moderate   2024-02-10  \n",
              "2                   caching_guide.md             moderate   2024-03-10  \n",
              "3  asynchronous programming_guide.md             moderate   2024-04-10  \n",
              "4            API versioning_guide.md             moderate   2024-05-10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-689fbb88-3c81-4b38-9ce2-db54e8769890\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>question</th>\n",
              "      <th>answer_snippet</th>\n",
              "      <th>source</th>\n",
              "      <th>confidence_indicator</th>\n",
              "      <th>last_updated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KB001</td>\n",
              "      <td>What are best practices for debugging?</td>\n",
              "      <td>When addressing debugging, it's important to f...</td>\n",
              "      <td>debugging_guide.md</td>\n",
              "      <td>moderate</td>\n",
              "      <td>2024-01-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KB002</td>\n",
              "      <td>What are best practices for performance tuning?</td>\n",
              "      <td>When addressing performance tuning, it's impor...</td>\n",
              "      <td>performance tuning_guide.md</td>\n",
              "      <td>moderate</td>\n",
              "      <td>2024-02-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KB003</td>\n",
              "      <td>What are best practices for caching?</td>\n",
              "      <td>When addressing caching, it's important to fol...</td>\n",
              "      <td>caching_guide.md</td>\n",
              "      <td>moderate</td>\n",
              "      <td>2024-03-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KB004</td>\n",
              "      <td>What are best practices for asynchronous progr...</td>\n",
              "      <td>When addressing asynchronous programming, it's...</td>\n",
              "      <td>asynchronous programming_guide.md</td>\n",
              "      <td>moderate</td>\n",
              "      <td>2024-04-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>KB005</td>\n",
              "      <td>What are best practices for API versioning?</td>\n",
              "      <td>When addressing API versioning, it's important...</td>\n",
              "      <td>API versioning_guide.md</td>\n",
              "      <td>moderate</td>\n",
              "      <td>2024-05-10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-689fbb88-3c81-4b38-9ce2-db54e8769890')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-689fbb88-3c81-4b38-9ce2-db54e8769890 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-689fbb88-3c81-4b38-9ce2-db54e8769890');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a64fd25f-ead4-4ae1-b020-8fafe26bb4f6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a64fd25f-ead4-4ae1-b020-8fafe26bb4f6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a64fd25f-ead4-4ae1-b020-8fafe26bb4f6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"doc_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"KB028\",\n          \"KB016\",\n          \"KB024\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"What are best practices for error handling?\",\n          \"What are best practices for performance tuning?\",\n          \"What are best practices for unit testing?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_snippet\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"When addressing error handling, it's important to follow well-defined patterns...\",\n          \"When addressing performance tuning, it's important to follow well-defined patterns...\",\n          \"When addressing unit testing, it's important to follow well-defined patterns...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"error handling_guide.md\",\n          \"performance tuning_guide.md\",\n          \"unit testing_guide.md\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"confidence_indicator\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"moderate\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"last_updated\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"2024-01-10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "VyyYVDI3ocFO",
        "outputId": "2a065a02-072f-4fc7-d30b-7b5c58578d0e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "doc_id                  30\n",
              "question                30\n",
              "answer_snippet          30\n",
              "source                  30\n",
              "confidence_indicator    30\n",
              "last_updated            30\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>doc_id</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>question</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>answer_snippet</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>confidence_indicator</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>last_updated</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "# os.environ['OPENAI_API_KEY'] = 'YOUR_API_KEY'\n",
        "# client = OpenAI()\n",
        "\n",
        "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
        "   text = text.replace(\"\\n\", \" \")\n",
        "   # Check if text is not empty or just whitespace\n",
        "   if text.strip():\n",
        "       try:\n",
        "           return client.embeddings.create(input = [text], model=AZURE_DEPLOYMENT_NAME).data[0].embedding\n",
        "\n",
        "       except Exception as e:\n",
        "           print(f\"Error getting embedding for text: {text}. Error: {e}\")\n",
        "           return None\n",
        "   else:\n",
        "       return None\n",
        "\n",
        "df['answer_embedding'] = df['answer_snippet'].apply(lambda x: get_embedding(x))\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "7-qtWow1ouSf",
        "outputId": "13448e93-dbc5-42b1-e0d6-a5995141dd5b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  doc_id                                           question  \\\n",
              "0  KB001             What are best practices for debugging?   \n",
              "1  KB002    What are best practices for performance tuning?   \n",
              "2  KB003               What are best practices for caching?   \n",
              "3  KB004  What are best practices for asynchronous progr...   \n",
              "4  KB005        What are best practices for API versioning?   \n",
              "\n",
              "                                      answer_snippet  \\\n",
              "0  When addressing debugging, it's important to f...   \n",
              "1  When addressing performance tuning, it's impor...   \n",
              "2  When addressing caching, it's important to fol...   \n",
              "3  When addressing asynchronous programming, it's...   \n",
              "4  When addressing API versioning, it's important...   \n",
              "\n",
              "                              source confidence_indicator last_updated  \\\n",
              "0                 debugging_guide.md             moderate   2024-01-10   \n",
              "1        performance tuning_guide.md             moderate   2024-02-10   \n",
              "2                   caching_guide.md             moderate   2024-03-10   \n",
              "3  asynchronous programming_guide.md             moderate   2024-04-10   \n",
              "4            API versioning_guide.md             moderate   2024-05-10   \n",
              "\n",
              "                                    answer_embedding  \n",
              "0  [-0.011498448438942432, 0.024632882326841354, ...  \n",
              "1  [-0.001747551723383367, 0.0041742464527487755,...  \n",
              "2  [0.002506050281226635, 0.02132047526538372, 0....  \n",
              "3  [-0.017202088609337807, -0.006009227130562067,...  \n",
              "4  [0.004086621105670929, -0.008509399369359016, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51e83ae6-e50f-4464-ae5f-db20c4a25b9d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>question</th>\n",
              "      <th>answer_snippet</th>\n",
              "      <th>source</th>\n",
              "      <th>confidence_indicator</th>\n",
              "      <th>last_updated</th>\n",
              "      <th>answer_embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KB001</td>\n",
              "      <td>What are best practices for debugging?</td>\n",
              "      <td>When addressing debugging, it's important to f...</td>\n",
              "      <td>debugging_guide.md</td>\n",
              "      <td>moderate</td>\n",
              "      <td>2024-01-10</td>\n",
              "      <td>[-0.011498448438942432, 0.024632882326841354, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KB002</td>\n",
              "      <td>What are best practices for performance tuning?</td>\n",
              "      <td>When addressing performance tuning, it's impor...</td>\n",
              "      <td>performance tuning_guide.md</td>\n",
              "      <td>moderate</td>\n",
              "      <td>2024-02-10</td>\n",
              "      <td>[-0.001747551723383367, 0.0041742464527487755,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KB003</td>\n",
              "      <td>What are best practices for caching?</td>\n",
              "      <td>When addressing caching, it's important to fol...</td>\n",
              "      <td>caching_guide.md</td>\n",
              "      <td>moderate</td>\n",
              "      <td>2024-03-10</td>\n",
              "      <td>[0.002506050281226635, 0.02132047526538372, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KB004</td>\n",
              "      <td>What are best practices for asynchronous progr...</td>\n",
              "      <td>When addressing asynchronous programming, it's...</td>\n",
              "      <td>asynchronous programming_guide.md</td>\n",
              "      <td>moderate</td>\n",
              "      <td>2024-04-10</td>\n",
              "      <td>[-0.017202088609337807, -0.006009227130562067,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>KB005</td>\n",
              "      <td>What are best practices for API versioning?</td>\n",
              "      <td>When addressing API versioning, it's important...</td>\n",
              "      <td>API versioning_guide.md</td>\n",
              "      <td>moderate</td>\n",
              "      <td>2024-05-10</td>\n",
              "      <td>[0.004086621105670929, -0.008509399369359016, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51e83ae6-e50f-4464-ae5f-db20c4a25b9d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-51e83ae6-e50f-4464-ae5f-db20c4a25b9d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-51e83ae6-e50f-4464-ae5f-db20c4a25b9d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0a75da5b-e40d-436c-bd87-0cf2d7f55761\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a75da5b-e40d-436c-bd87-0cf2d7f55761')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0a75da5b-e40d-436c-bd87-0cf2d7f55761 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"doc_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"KB028\",\n          \"KB016\",\n          \"KB024\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"What are best practices for error handling?\",\n          \"What are best practices for performance tuning?\",\n          \"What are best practices for unit testing?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_snippet\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"When addressing error handling, it's important to follow well-defined patterns...\",\n          \"When addressing performance tuning, it's important to follow well-defined patterns...\",\n          \"When addressing unit testing, it's important to follow well-defined patterns...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"error handling_guide.md\",\n          \"performance tuning_guide.md\",\n          \"unit testing_guide.md\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"confidence_indicator\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"moderate\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"last_updated\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"2024-01-10\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qdrant-client --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnUyEQOL6SEf",
        "outputId": "d38c439d-e185-4c22-ce8a-cfd76d6c4f96"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/327.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.7/327.7 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai langgraph dotenv --quiet\n",
        "#!pip install -U langgraph --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPc3rFqVsCz2",
        "outputId": "2280621e-f3a7-445e-fd91-d942908f669c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.4/65.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.1/438.1 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import QdrantClient\n",
        "from typing import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from dotenv import load_dotenv\n",
        "from langgraph.graph import Graph\n",
        "from typing import List, Dict"
      ],
      "metadata": {
        "id": "GRGvtDElr2Bz"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "qdrant_client = QdrantClient(\n",
        "    url=\"https://42589af0-252c-4406-af8f-138a66e7ebd6.us-west-1-0.aws.cloud.qdrant.io:6333\",\n",
        "    api_key=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.x_9qUfpk8fyUI3SijtVffgcNJlDLk186e8_6PJZyluc\",\n",
        ")\n",
        "\n",
        "print(qdrant_client.get_collections())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw2YoI9M1UDW",
        "outputId": "44101a42-8ef4-4137-d71b-1f1125ca3b4d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "collections=[CollectionDescription(name='kb_index')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Upsert to Vector Store using Qdrant\n",
        "\n",
        "from qdrant_client.http.models import Distance, VectorParams, PointStruct\n",
        "from qdrant_client import models\n",
        "\n",
        "# Create an index (collection)\n",
        "collection_name = \"kb_index\"\n",
        "\n",
        "# Get the dimension of the embeddings from the first valid embedding\n",
        "embedding_dimension = len(df.loc[df['answer_embedding'].notna(), 'answer_embedding'].iloc[0])\n",
        "\n",
        "qdrant_client.recreate_collection(\n",
        "    collection_name=collection_name,\n",
        "    vectors_config=VectorParams(size=embedding_dimension, distance=Distance.COSINE)\n",
        ")\n",
        "\n",
        "# Prepare data for upserting\n",
        "points_to_upsert = []\n",
        "for index, row in df.iterrows():\n",
        "    if row['answer_embedding'] is not None:\n",
        "        points_to_upsert.append(\n",
        "            PointStruct(\n",
        "                id=index,  # Use the DataFrame index as the point ID\n",
        "                vector=row['answer_embedding'],\n",
        "                payload={\"answer_snippet\": row['answer_snippet']} # Store the answer snippet in the payload\n",
        "            )\n",
        "        )\n",
        "\n",
        "# Upsert the data in batches\n",
        "batch_size = 100\n",
        "for i in tqdm(range(0, len(points_to_upsert), batch_size), desc=\"Upserting to Qdrant\"):\n",
        "    batch = points_to_upsert[i:i + batch_size]\n",
        "    qdrant_client.upsert(\n",
        "        collection_name=collection_name,\n",
        "        wait=True,\n",
        "        points=batch\n",
        "    )\n",
        "\n",
        "print(f\"Upserted {len(points_to_upsert)} points to collection '{collection_name}'.\")\n",
        "print(qdrant_client.count(collection_name=collection_name, exact=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqhABphc7rux",
        "outputId": "9fb4ed76-c7fe-4805-d45c-cc04d0fb07a8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-686222941>:12: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
            "  qdrant_client.recreate_collection(\n",
            "Upserting to Qdrant: 100%|██████████| 1/1 [00:00<00:00,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upserted 30 points to collection 'kb_index'.\n",
            "count=30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleState(TypedDict):\n",
        "    query:str\n",
        "    kb_hits:str\n",
        "    critique_result:str\n",
        "    refined_answer:str\n"
      ],
      "metadata": {
        "id": "718hlO1K5Nn5"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Retriever Node\n",
        "\n",
        "\n",
        "# Modify retrieve_kb to accept the state dictionary and extract user_question\n",
        "def retrieve_kb(state: Dict) -> Dict:\n",
        "    \"\"\"\n",
        "    Retrieves relevant knowledge base hits based on the user's question from the state.\n",
        "    \"\"\"\n",
        "    user_question = state.get(\"user_question\", \"\")\n",
        "    if not user_question:\n",
        "        return {\"kb_hits\": []}\n",
        "\n",
        "    question_embedding = get_embedding(user_question)\n",
        "    if question_embedding is None:\n",
        "        return {\"kb_hits\": []}\n",
        "\n",
        "    # Assuming qdrant_client and collection_name are defined above\n",
        "    search_result = qdrant_client.search(\n",
        "        collection_name=collection_name,\n",
        "        query_vector=question_embedding,\n",
        "        limit=5  # Get the top 5 most similar answer_snippet vectors\n",
        "    )\n",
        "\n",
        "    kb_hits = []\n",
        "    for hit in search_result:\n",
        "        # Assuming your payload contains 'answer_snippet' and 'source'\n",
        "        # Modify based on your actual payload structure\n",
        "        kb_hits.append({\n",
        "            \"doc_id\": hit.id,\n",
        "            \"answer_snippet\": hit.payload.get(\"answer_snippet\", \"\"),\n",
        "            # You might need to add a 'source' field to your Qdrant payload\n",
        "            # if it's not already there.\n",
        "            \"source\": hit.payload.get(\"source\", \"unknown\")\n",
        "        })\n",
        "    return {\"kb_hits\": kb_hits}\n",
        "\n",
        "# Define the graph\n",
        "workflow = StateGraph()\n",
        "\n",
        "# Add the retrieve_kb node\n",
        "workflow.add_node(\"retrieve_kb\", retrieve_kb)\n",
        "workflow.add_edge(START, \"retrieve_kb\")\n",
        "workflow.add_edge(\"chat1\",END)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "2ggg-AhXraRB",
        "outputId": "8d8aa1e8-9dc2-4da1-81ab-884d8ca0e430"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Must provide state_schema or input and output",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-137-181054348>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Define the graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mworkflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStateGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Add the retrieve_kb node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/graph/state.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, state_schema, config_schema, input, output)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate_schema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must provide state_schema or input and output\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0mstate_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValueError\u001b[0m: Must provide state_schema or input and output"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "workflow"
      ],
      "metadata": {
        "id": "9qpHiWVeCRoc",
        "outputId": "ff18c999-e873-4bd3-b110-bb40b10b8bf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x78e0ff23db50>"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. LLM Answer Node\n",
        "\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "import os # Import the os module to access environment variables\n",
        "\n",
        "# Define the prompt template for the LLM Answer Node\n",
        "llm_answer_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"You are a software best-practices assistant.\n",
        "User Question:\n",
        "{user_question}\n",
        "Retrieved Snippets:\n",
        "{kb_snippets}\n",
        "Task:\n",
        "Based on these snippets, write a concise answer to the user’s question.\n",
        "Cite each snippet you use by its doc_id in square brackets (e.g., [KB004]).\n",
        "Return only the answer text.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# Helper function to format KB hits for the prompt\n",
        "def format_kb_hits_for_prompt(kb_hits: List[Dict]) -> str:\n",
        "    formatted_snippets = []\n",
        "    for hit in kb_hits:\n",
        "        formatted_snippets.append(f\"[{hit['doc_id']}] {hit['answer_snippet']}\")\n",
        "    return \"\\n\".join(formatted_snippets)\n",
        "\n",
        "# Define the LLM Answer Node function\n",
        "def generate_answer(user_question: str, kb_hits: List[Dict]) -> str:\n",
        "    \"\"\"\n",
        "    Generates an initial answer based on retrieved knowledge base snippets.\n",
        "    \"\"\"\n",
        "    llm = AzureChatOpenAI(\n",
        "        azure_endpoint=os.getenv(\"OPENAI_ENDPOINT\"),\n",
        "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "        api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
        "        deployment_name=\"gpt-4\" # Or \"gpt-3.5-turbo\" based on your preference\n",
        "    )\n",
        "\n",
        "    chain = (\n",
        "        {\n",
        "            \"user_question\": lambda x: x[\"user_question\"],\n",
        "            \"kb_snippets\": lambda x: format_kb_hits_for_prompt(x[\"kb_hits\"])\n",
        "        }\n",
        "        | llm_answer_prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    response = chain.invoke({\"user_question\": user_question, \"kb_hits\": kb_hits})\n",
        "    return {\"initial_answer\": response}\n",
        "\n",
        "\n",
        "# Add the generate_answer node\n",
        "workflow.add_node(\"generate_answer\", generate_answer)\n",
        "\n",
        "# Add an edge from retrieve_kb to generate_answer\n",
        "workflow.add_edge('retrieve_kb', 'generate_answer')\n",
        "\n",
        "# Set the entry point\n",
        "workflow.set_entry_point(\"retrieve_kb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f119497-7e8d-411c-ac17-fd6b9ca2a5c8",
        "id": "fGu2E-r3roAC"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x78e0ff0258d0>"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. critique_answer\n",
        "\n",
        "# Define the prompt template for the Self-Critique Node\n",
        "critique_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"You are a critical QA assistant. The user asked: {user_question}\n",
        "Initial Answer:\n",
        "{initial_answer}\n",
        "KB Snippets:\n",
        "{kb_snippets}\n",
        "Task:\n",
        "Determine if the initial answer fully addresses the question using only these snippets.\n",
        "- If it does, respond exactly: COMPLETE\n",
        "- If it misses any point or cites missing info, respond: REFINE: <short list of missing topic keywords>\n",
        "Return exactly one line.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# Define the Self-Critique Node function\n",
        "def critique_answer(user_question: str, initial_answer: str, kb_hits: List[Dict]) -> str:\n",
        "    \"\"\"\n",
        "    Critiques the initial answer based on the retrieved knowledge base snippets.\n",
        "    \"\"\"\n",
        "    llm = AzureChatOpenAI(\n",
        "        azure_endpoint=os.getenv(\"OPENAI_ENDPOINT\"),\n",
        "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "        api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
        "        deployment_name=\"gpt-4\"\n",
        "    )\n",
        "\n",
        "    chain = (\n",
        "        {\n",
        "            \"user_question\": lambda x: x[\"user_question\"],\n",
        "            \"initial_answer\": lambda x: x[\"initial_answer\"],\n",
        "            \"kb_snippets\": lambda x: format_kb_hits_for_prompt(x[\"kb_hits\"])\n",
        "        }\n",
        "        | critique_prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    critique_result = chain.invoke({\"user_question\": user_question, \"initial_answer\": initial_answer, \"kb_hits\": kb_hits})\n",
        "    return {\"critique_result\": critique_result}\n",
        "\n",
        "# Add the critique_answer node\n",
        "workflow.add_node(\"critique_answer\", critique_answer)\n",
        "\n",
        "# Add an edge from generate_answer to critique_answer\n",
        "workflow.add_edge('generate_answer', 'critique_answer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zfy5jBswrkr4",
        "outputId": "2419ee9e-414e-43a7-a75f-5459e8136543"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x78e0ff0258d0>"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4th Node\n",
        "\n",
        "import re # Import regex for extracting keywords\n",
        "\n",
        "# Define the prompt template for the Refinement Node\n",
        "refinement_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"You are a software best-practices assistant refining your answer. The user asked: {user_question}\n",
        "Initial Answer:\n",
        "{initial_answer}\n",
        "Critique: {critique_result}\n",
        "Additional Snippet:\n",
        "[{additional_snippet_doc_id}] {additional_snippet_text}\n",
        "Task:\n",
        "Incorporate this snippet into the answer, covering the missing points.\n",
        "Cite any snippet you use by doc_id in square brackets.\n",
        "Return only the final refined answer.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# Define the Refinement Node function\n",
        "def refine_answer(user_question: str, initial_answer: str, critique_result: str, kb_hits: List[Dict]) -> str:\n",
        "    \"\"\"\n",
        "    Refines the initial answer based on the critique and an additional knowledge base hit.\n",
        "    \"\"\"\n",
        "    llm = AzureChatOpenAI(\n",
        "        azure_endpoint=os.getenv(\"OPENAI_ENDPOINT\"),\n",
        "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "        api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
        "        deployment_name=\"gpt-4\"\n",
        "    )\n",
        "\n",
        "    # 1. Extract missing-topic keywords from critique_result\n",
        "    missing_keywords = \"\"\n",
        "    match = re.search(r\"REFINE: (.+)\", critique_result)\n",
        "    if match:\n",
        "        missing_keywords = match.group(1).strip()\n",
        "\n",
        "    # 2. Build a new query string\n",
        "    new_query = f\"{user_question} and information on {missing_keywords}\" if missing_keywords else user_question\n",
        "\n",
        "    # 3. Call the same retriever function to get one additional snippet (top_k=1) for that new_query.\n",
        "    # We need to modify the retrieve_kb function or create a new one that takes a limit parameter.\n",
        "    # For now, let's simulate this by getting the top 1 hit for the new query.\n",
        "    # This assumes get_embedding and qdrant_client are accessible in this scope.\n",
        "    additional_snippet = None\n",
        "    if new_query:\n",
        "        query_embedding = get_embedding(new_query)\n",
        "        if query_embedding is not None:\n",
        "            search_result = qdrant_client.search(\n",
        "                collection_name=collection_name,\n",
        "                query_vector=query_embedding,\n",
        "                limit=1  # Get only the top 1 hit\n",
        "            )\n",
        "            if search_result:\n",
        "                hit = search_result[0]\n",
        "                additional_snippet = {\n",
        "                    \"doc_id\": hit.id,\n",
        "                    \"text\": hit.payload.get(\"answer_snippet\", \"\")\n",
        "                }\n",
        "\n",
        "    # Prepare data for the refinement prompt\n",
        "    additional_snippet_doc_id = \"\"\n",
        "    additional_snippet_text = \"No additional relevant snippet found.\"\n",
        "    if additional_snippet:\n",
        "        additional_snippet_doc_id = additional_snippet[\"doc_id\"]\n",
        "        additional_snippet_text = additional_snippet[\"text\"]\n",
        "\n",
        "\n",
        "    chain = (\n",
        "        {\n",
        "            \"user_question\": lambda x: x[\"user_question\"],\n",
        "            \"initial_answer\": lambda x: x[\"initial_answer\"],\n",
        "            \"critique_result\": lambda x: x[\"critique_result\"],\n",
        "            \"additional_snippet_doc_id\": lambda x: x[\"additional_snippet_doc_id\"],\n",
        "            \"additional_snippet_text\": lambda x: x[\"additional_snippet_text\"]\n",
        "        }\n",
        "        | refinement_prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    refined_answer = chain.invoke({\n",
        "        \"user_question\": user_question,\n",
        "        \"initial_answer\": initial_answer,\n",
        "        \"critique_result\": critique_result,\n",
        "        \"additional_snippet_doc_id\": additional_snippet_doc_id,\n",
        "        \"additional_snippet_text\": additional_snippet_text\n",
        "    })\n",
        "\n",
        "    return {\"refined_answer\": refined_answer}\n",
        "\n",
        "# Add the refine_answer node\n",
        "workflow.add_node(\"refine_answer\", refine_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVDYyKeL7dsD",
        "outputId": "62939bcb-f723-487d-c8c9-fb98e4773c9c"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.graph.Graph at 0x78e0ff0258d0>"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: code for graph control flow . Wire nodes in sequence:\n",
        "# 1. retrieve_kb → generate_answer → critique_answer.\n",
        "# 2. Add a simple Decision node (or an if check in your driver script) that:\n",
        "# If critique_result == \"COMPLETE\", take initial_answer as final.\n",
        "# If critique_result.startswith(\"REFINE\"), call the refinement logic (retrieve+refine) to produce refined_answer.\n",
        "# 3. Wrap whichever answer (initial or refined) into a JSON response:\n",
        "# { \"answer\": \"<final_answer_text>\" }\n",
        "\n",
        "from langgraph.graph import END # Import END for conditional edges\n",
        "from typing import TypedDict, List, Dict # Import TypedDict, List, and Dict for state definition\n",
        "\n",
        "# Add a conditional edge from critique_answer based on critique_result\n",
        "def decide_action(state: Dict) -> str:\n",
        "    \"\"\"\n",
        "    Decides whether to complete the process or refine the answer based on the critique result.\n",
        "    \"\"\"\n",
        "    critique_result = state.get(\"critique_result\", \"\")\n",
        "    if critique_result == \"COMPLETE\":\n",
        "        return \"complete\"\n",
        "    elif critique_result.startswith(\"REFINE\"):\n",
        "        return \"refine\"\n",
        "    else:\n",
        "        # Handle unexpected critique results or default to refinement\n",
        "        print(f\"Warning: Unexpected critique result: {critique_result}. Defaulting to refine.\")\n",
        "        return \"refine\"\n",
        "\n",
        "\n",
        "# Add the decision node using add_conditional_edges\n",
        "workflow.add_conditional_edges(\n",
        "    'critique_answer',  # Source node\n",
        "    decide_action,      # Decision function\n",
        "    {\n",
        "        \"complete\": END,  # If decide_action returns \"complete\", go to END\n",
        "        \"refine\": \"refine_answer\" # If decide_action returns \"refine\", go to refine_answer\n",
        "    }\n",
        ")\n",
        "\n",
        "# Add an edge from refine_answer to END (after refinement, the process is considered complete)\n",
        "workflow.add_edge(\"refine_answer\", END)\n",
        "\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "# Define the input state type for the graph (optional, but good practice)\n",
        "# This definition seems to be from a previous attempt and might not be strictly necessary\n",
        "# depending on how the state is managed, but keeping it for now.\n",
        "\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "user_question = \"What is the best practice for logging errors?\"\n",
        "# The input to the graph should match the expected input of the entry point node.\n",
        "# The entry point is START, and the first node is retrieve_kb, which expects user_question in the state.\n",
        "inputs = {\"user_question\": user_question}\n",
        "\n",
        "# Run the graph\n",
        "final_state = app.invoke(inputs)\n",
        "\n",
        "# Wrap the final answer in JSON format\n",
        "# The final answer will be in either 'initial_answer' or 'refined_answer' depending on the path taken.\n",
        "final_answer_text = final_state.get(\"refined_answer\") if \"refined_answer\" in final_state else final_state.get(\"initial_answer\", \"No answer generated.\")\n",
        "\n",
        "response_json = {\n",
        "    \"answer\": final_answer_text\n",
        "}\n",
        "\n",
        "import json\n",
        "print(json.dumps(response_json, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "BxdXPsmt7pzk",
        "outputId": "545a9b89-c970-48c6-fcfe-94f59a3bc92c"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found edge starting at unknown node 'refine_answer'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-139-4160722473>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Compile the graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Define the input state type for the graph (optional, but good practice)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/graph/graph.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, checkpointer, interrupt_before, interrupt_after, debug, name, cache, store)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;31m# validate the graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         self.validate(\n\u001b[0m\u001b[1;32m    350\u001b[0m             interrupt=(\n\u001b[1;32m    351\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0minterrupt_before\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minterrupt_before\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minterrupt_after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/graph/graph.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, interrupt)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_sources\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msource\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mSTART\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Found edge starting at unknown node '{source}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mSTART\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_sources\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found edge starting at unknown node 'refine_answer'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BLjSi3tOrkXs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}